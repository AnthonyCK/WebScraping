{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10035b41",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a3b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "# Get the URL of all the products in a list and create scraping log \n",
    "log = []\n",
    "products = []\n",
    "for i in range(486,633):\n",
    "    products.append(f'http://di75wax.devweb.mwn.de/static/product/{i}.html')\n",
    "    url = (f'http://di75wax.devweb.mwn.de/static/product/{i}.html')\n",
    "    if requests.get(url).status_code == 200: \n",
    "        log.append({\"url\":url, \"message\": \"Success\"})\n",
    "    else:\n",
    "        log.append({\"url\":url, \"message\": \"Fail\"})  \n",
    "pd.DataFrame(log).to_csv(\"logging.csv\",sep=\";\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419a0cf",
   "metadata": {},
   "source": [
    "# Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d73088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the html files\n",
    "import requests \n",
    "for i in range(0,len(products)):\n",
    "    page = requests.get(products[i])\n",
    "    with open(f'product_url_{i}.html', 'wb+') as f:\n",
    "        f.write(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3ae28",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e536ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "variable_list = []\n",
    "for i in range(0,len(products)):\n",
    "    with open(f\"product_url_{i}.html\") as file:\n",
    "        soup = bs(file, \"html.parser\")\n",
    "            \n",
    "    # Price, Name and Description \n",
    "    name_price_des = soup.find('div',  {\"class\":\"caption\"}).text\n",
    "    result_1 = name_price_des.split('\\n')\n",
    "    result_2 = ','.join(filter(None, result_1))\n",
    "    price = result_2.split(',')[0][1:]\n",
    "    name = result_2.split(',')[1]\n",
    "    description = soup.find('p',  {\"class\":\"description\"}).text\n",
    "\n",
    "\n",
    "    # Number of reviews \n",
    "    results_3 = soup.find('div',  {\"class\":\"ratings\"}).text\n",
    "    reviews = re.findall(r'\\d+', results_3)\n",
    "\n",
    "    # Product rating (Number of stars)\n",
    "    results_4 = str(soup.find('div',  {\"class\":\"ratings\"}))\n",
    "    stars = results_4.count('glyphicon-star')\n",
    "\n",
    "    # Colors (if available)\n",
    "    try: \n",
    "        dropdown = soup.find('div',  {\"class\":\"dropdown\"}).text\n",
    "        result_5 = dropdown.split('\\n')\n",
    "        result_6 = ','.join(filter(None, result_5[1:]))\n",
    "        result_7 = result_6.split(',')[1:]\n",
    "        colors =  '/'.join(result_7)\n",
    "    except: \n",
    "        colors = \"\"\n",
    "    \n",
    "    # Capacity (if available)\n",
    "    try: \n",
    "        capacity = soup.findAll(\"button\", {\"type\": \"button\"})\n",
    "        capacity = \"/\".join([store.text for store in capacity if len(re.findall(\"disabled\", str(store)))==0])\n",
    "    except: \n",
    "        capacity = \"\"\n",
    "    \n",
    "    ## alles zu einer row zusammenfügen und später in einer Loop über alle Beobachtungen zusammen speichern \n",
    "    product = {\"ID\": i+486, \"name\":name, \"price\":price, \"description\":description, \"reviews\":reviews[0], \"stars\":stars, \"colors\":colors, \"capacity\":capacity}\n",
    "    variable_list.append(product)\n",
    "  \n",
    "# make it a dataframe\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(variable_list)\n",
    "\n",
    "\n",
    "# Product category L1 \n",
    "# range: 516 - 632 = Computer, Laptop \n",
    "# 495 - 515: Computer, Tablet \n",
    "# 486 - 494: Phone, Touch \n",
    "data.loc[(data[\"ID\"]>=486)&(data[\"ID\"]<495), \"L1\"] = \"Phone\"\n",
    "data.loc[(data[\"ID\"]>=495)&(data[\"ID\"]<633), \"L1\"] = \"Computer\"\n",
    "\n",
    "# Product category L2\n",
    "data.loc[(data[\"ID\"]>=486)&(data[\"ID\"]<495), \"L2\"] = \"Touch\"\n",
    "data.loc[(data[\"ID\"]>=495)&(data[\"ID\"]<516), \"L2\"] = \"Tablet\"\n",
    "data.loc[(data[\"ID\"]>=516)&(data[\"ID\"]<633), \"L2\"] = \"Laptop\"\n",
    "\n",
    "\n",
    "data = data[['ID', 'L1', 'L2', 'name', 'price', 'description', 'stars', 'reviews', 'colors', 'capacity']]\n",
    " \n",
    "data.to_csv(\"product_list.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv \n",
    "import csv\n",
    "with open('product_list', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(url)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
